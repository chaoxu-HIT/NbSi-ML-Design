{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e466350-453b-42aa-b247-42855a37204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始多模型SHAP分析（修复版）===\n",
      "输出目录: D:\\博一下\\manuscript5-变Si组\\SHAP分析8.1.3\n",
      "分析时间: 2025-08-02 21:22:44\n",
      "\n",
      "=== 加载原始数据 ===\n",
      "✓ 成功加载数据: (221, 104)\n",
      "\n",
      "=== 加载所有最佳模型相关数据 ===\n",
      "✓ 成功加载所有保存的数据\n",
      "✓ 找到 11 个最佳模型\n",
      "\n",
      "=== 开始多模型SHAP分析（修复版）===\n",
      "总计模型数量: 11\n",
      "\n",
      "[1/11] 分析模型: PCC_k=5_GradientBoosting\n",
      "  方法: PCC, 模型: GradientBoosting, K=5\n",
      "  Test R²: 0.9318, Test MAE: 2.0637\n",
      "  准备模型数据: PCC_k=5_GradientBoosting\n",
      "    特征: ['mean_C4 enthalpy melting', 'solubility_limit_factor', 'mean_S10 Lattice Constants a', 'Λ', 'Ω']\n",
      "    特征索引: [10 33 12  8  7]\n",
      "    模型输入数据形状: (221, 5)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [4.6582, 61.5129]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 5)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493211\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493211\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 59: Base=12.081340, Step1_计算=13.010624, Step1_实际=13.010624, 匹配=True\n",
      "        样本 200: Base=12.081340, Step1_计算=10.478731, Step1_实际=10.478731, 匹配=True\n",
      "        样本 187: Base=12.081340, Step1_计算=9.992377, Step1_实际=9.992377, 匹配=True\n",
      "        样本 138: Base=12.081340, Step1_计算=13.051563, Step1_实际=13.051563, 匹配=True\n",
      "        样本 174: Base=12.081340, Step1_计算=14.993502, Step1_实际=14.993502, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493211\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=10.442705, Step1_实际=10.442705, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=21.473211, Step1_实际=21.473211, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=12.825104, Step1_实际=12.825104, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=8.237347, Step1_实际=8.237347, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=10.015963, Step1_实际=10.015963, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 PCC_k=5_GradientBoosting 分析完成 (耗时: 8.3秒)\n",
      "\n",
      "[2/11] 分析模型: F-Regression_k=5_GradientBoosting\n",
      "  方法: F-Regression, 模型: GradientBoosting, K=5\n",
      "  Test R²: 0.9197, Test MAE: 2.0991\n",
      "  准备模型数据: F-Regression_k=5_GradientBoosting\n",
      "    特征: ['Ω', 'Λ', 'mean_C4 enthalpy melting', 'mean_S10 Lattice Constants a', 'solubility_limit_factor']\n",
      "    特征索引: [ 7  8 10 12 33]\n",
      "    模型输入数据形状: (221, 5)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [4.6582, 61.5129]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 5)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493211\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493211\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 138: Base=12.081340, Step1_计算=13.049463, Step1_实际=13.049463, 匹配=True\n",
      "        样本 182: Base=12.081340, Step1_计算=9.848165, Step1_实际=9.848165, 匹配=True\n",
      "        样本 211: Base=12.081340, Step1_计算=8.144572, Step1_实际=8.144572, 匹配=True\n",
      "        样本 7: Base=12.081340, Step1_计算=10.500168, Step1_实际=10.500168, 匹配=True\n",
      "        样本 103: Base=12.081340, Step1_计算=12.833320, Step1_实际=12.833320, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493211\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=10.445182, Step1_实际=10.445182, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=20.632128, Step1_实际=20.632128, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=12.822515, Step1_实际=12.822515, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=8.279410, Step1_实际=8.279410, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=10.034513, Step1_实际=10.034513, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 F-Regression_k=5_GradientBoosting 分析完成 (耗时: 7.7秒)\n",
      "\n",
      "[3/11] 分析模型: RFE_k=4_GradientBoosting\n",
      "  方法: RFE, 模型: GradientBoosting, K=4\n",
      "  Test R²: 0.9177, Test MAE: 2.2332\n",
      "  准备模型数据: RFE_k=4_GradientBoosting\n",
      "    特征: ['Ω', 'mean_Mass Magnetic Susceptibility', 'var_C2 temperature boiling', 'var_Mass Magnetic Susceptibility']\n",
      "    特征索引: [ 7 11 20 24]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.3567, 61.1935]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493215\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493215\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 79: Base=12.081340, Step1_计算=12.939938, Step1_实际=12.939938, 匹配=True\n",
      "        样本 194: Base=12.081340, Step1_计算=10.770376, Step1_实际=10.770376, 匹配=True\n",
      "        样本 127: Base=12.081340, Step1_计算=10.482833, Step1_实际=10.482833, 匹配=True\n",
      "        样本 126: Base=12.081340, Step1_计算=10.240639, Step1_实际=10.240639, 匹配=True\n",
      "        样本 55: Base=12.081340, Step1_计算=9.927979, Step1_实际=9.927979, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493215\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=10.553517, Step1_实际=10.553517, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=9.624067, Step1_实际=9.624067, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=10.489029, Step1_实际=10.489029, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=7.776297, Step1_实际=7.776297, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=10.858508, Step1_实际=10.858508, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 RFE_k=4_GradientBoosting 分析完成 (耗时: 7.2秒)\n",
      "\n",
      "[4/11] 分析模型: Mutual Information_k=5_GradientBoosting\n",
      "  方法: Mutual Information, 模型: GradientBoosting, K=5\n",
      "  Test R²: 0.9157, Test MAE: 2.1871\n",
      "  准备模型数据: Mutual Information_k=5_GradientBoosting\n",
      "    特征: ['x', 'δ', 'Λ', 'mean_C4 enthalpy melting', 'var_C4 enthalpy melting']\n",
      "    特征索引: [ 4  6  8 10 21]\n",
      "    模型输入数据形状: (221, 5)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [4.5523, 61.4253]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 5)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493216\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493216\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 109: Base=12.081340, Step1_计算=11.510443, Step1_实际=11.510443, 匹配=True\n",
      "        样本 70: Base=12.081340, Step1_计算=9.871000, Step1_实际=9.871000, 匹配=True\n",
      "        样本 184: Base=12.081340, Step1_计算=11.780389, Step1_实际=11.780389, 匹配=True\n",
      "        样本 78: Base=12.081340, Step1_计算=12.386128, Step1_实际=12.386128, 匹配=True\n",
      "        样本 43: Base=12.081340, Step1_计算=12.207781, Step1_实际=12.207781, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493216\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=9.953720, Step1_实际=9.953720, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=32.321106, Step1_实际=32.321106, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=12.238677, Step1_实际=12.238677, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=9.089792, Step1_实际=9.089792, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=11.579247, Step1_实际=11.579247, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 Mutual Information_k=5_GradientBoosting 分析完成 (耗时: 7.7秒)\n",
      "\n",
      "[5/11] 分析模型: Lasso_k=4_GradientBoosting\n",
      "  方法: Lasso, 模型: GradientBoosting, K=4\n",
      "  Test R²: 0.9149, Test MAE: 2.1957\n",
      "  准备模型数据: Lasso_k=4_GradientBoosting\n",
      "    特征: ['var_电导率(MS/m)', 'mean_Mass Magnetic Susceptibility', 'var_E13 Electron affinity', 'var_Mass Magnetic Susceptibility']\n",
      "    特征索引: [28 11 22 24]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [6.0086, 61.2042]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493211\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493211\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 198: Base=12.081340, Step1_计算=10.546277, Step1_实际=10.546277, 匹配=True\n",
      "        样本 99: Base=12.081340, Step1_计算=10.657946, Step1_实际=10.657946, 匹配=True\n",
      "        样本 194: Base=12.081340, Step1_计算=11.020806, Step1_实际=11.020806, 匹配=True\n",
      "        样本 188: Base=12.081340, Step1_计算=10.088792, Step1_实际=10.088792, 匹配=True\n",
      "        样本 44: Base=12.081340, Step1_计算=10.020450, Step1_实际=10.020450, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493211\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=10.960098, Step1_实际=10.960098, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=30.082319, Step1_实际=30.082319, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=11.189716, Step1_实际=11.189716, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=10.144379, Step1_实际=10.144379, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=10.651227, Step1_实际=10.651227, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 Lasso_k=4_GradientBoosting 分析完成 (耗时: 7.2秒)\n",
      "\n",
      "[6/11] 分析模型: SFS_k=4_GradientBoosting\n",
      "  方法: SFS, 模型: GradientBoosting, K=4\n",
      "  Test R²: 0.9103, Test MAE: 2.1015\n",
      "  准备模型数据: SFS_k=4_GradientBoosting\n",
      "    特征: ['Ω', 'mean_C4 enthalpy melting', 'var_C12 modulus Young', 'var_Space Group Number']\n",
      "    特征索引: [7, 10, 19, 17]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.1227, 61.5474]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493211\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493211\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 131: Base=12.081340, Step1_计算=13.469001, Step1_实际=13.469001, 匹配=True\n",
      "        样本 201: Base=12.081340, Step1_计算=10.063553, Step1_实际=10.063553, 匹配=True\n",
      "        样本 64: Base=12.081340, Step1_计算=12.899129, Step1_实际=12.899129, 匹配=True\n",
      "        样本 29: Base=12.081340, Step1_计算=12.446369, Step1_实际=12.446369, 匹配=True\n",
      "        样本 32: Base=12.081340, Step1_计算=12.540224, Step1_实际=12.540224, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493211\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=9.944851, Step1_实际=9.944851, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=26.208397, Step1_实际=26.208397, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=12.303455, Step1_实际=12.303455, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=8.342070, Step1_实际=8.342070, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=12.494143, Step1_实际=12.494143, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 SFS_k=4_GradientBoosting 分析完成 (耗时: 6.9秒)\n",
      "\n",
      "[7/11] 分析模型: RandomForest_k=4_GradientBoosting\n",
      "  方法: RandomForest, 模型: GradientBoosting, K=4\n",
      "  Test R²: 0.9082, Test MAE: 2.1780\n",
      "  准备模型数据: RandomForest_k=4_GradientBoosting\n",
      "    特征: ['mean_S10 Lattice Constants a', 'mean_Mass Magnetic Susceptibility', 'mean_C4 enthalpy melting', 'Ω']\n",
      "    特征索引: [12 11 10  7]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.0115, 61.5940]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493207\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493207\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 43: Base=12.081340, Step1_计算=13.230892, Step1_实际=13.230892, 匹配=True\n",
      "        样本 144: Base=12.081340, Step1_计算=8.043009, Step1_实际=8.043009, 匹配=True\n",
      "        样本 211: Base=12.081340, Step1_计算=7.854429, Step1_实际=7.854429, 匹配=True\n",
      "        样本 23: Base=12.081340, Step1_计算=12.697569, Step1_实际=12.697569, 匹配=True\n",
      "        样本 218: Base=12.081340, Step1_计算=12.696354, Step1_实际=12.696354, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493207\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=10.260908, Step1_实际=10.260908, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=16.236630, Step1_实际=16.236630, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=13.044597, Step1_实际=13.044597, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=8.044640, Step1_实际=8.044640, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=12.298846, Step1_实际=12.298846, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 RandomForest_k=4_GradientBoosting 分析完成 (耗时: 6.9秒)\n",
      "\n",
      "[8/11] 分析模型: SFS_k=4_Bagging\n",
      "  方法: SFS, 模型: Bagging, K=4\n",
      "  Test R²: 0.9080, Test MAE: 2.2937\n",
      "  准备模型数据: SFS_k=4_Bagging\n",
      "    特征: ['Ω', 'mean_C4 enthalpy melting', 'var_C12 modulus Young', 'var_Space Group Number']\n",
      "    特征索引: [7, 10, 19, 17]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.9380, 56.9700]\n",
      "  创建SHAP解释器...\n",
      "    TreeExplainer失败，尝试Explainer: Model type not yet supported by TreeExplainer: <class 'sklearn.ensemble._bagging.BaggingRegressor'>\n",
      "    Explainer失败，使用KernelExplainer: The passed model is not callable and cannot be analyzed directly with the given masker! Model: BaggingRegressor(n_jobs=4, random_state=2023)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8557dcfe64405eb5a9290abf03d400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ KernelExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 10.912167566666666\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 10.912167566666666\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 89: Base=10.912168, Step1_计算=8.856226, Step1_实际=8.856226, 匹配=True\n",
      "        样本 197: Base=10.912168, Step1_计算=8.699535, Step1_实际=8.699535, 匹配=True\n",
      "        样本 3: Base=10.912168, Step1_计算=11.114919, Step1_实际=11.114919, 匹配=True\n",
      "        样本 188: Base=10.912168, Step1_计算=9.560951, Step1_实际=9.560951, 匹配=True\n",
      "        样本 107: Base=10.912168, Step1_计算=11.606472, Step1_实际=11.606472, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 10.912167566666666\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=10.912168, Step1_计算=8.909512, Step1_实际=8.909512, 匹配=True\n",
      "        样本 2: Base=10.912168, Step1_计算=21.197639, Step1_实际=21.197639, 匹配=True\n",
      "        样本 3: Base=10.912168, Step1_计算=11.114919, Step1_实际=11.114919, 匹配=True\n",
      "        样本 4: Base=10.912168, Step1_计算=7.326715, Step1_实际=7.326715, 匹配=True\n",
      "        样本 5: Base=10.912168, Step1_计算=11.785824, Step1_实际=11.785824, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 SFS_k=4_Bagging 分析完成 (耗时: 39.2秒)\n",
      "\n",
      "[9/11] 分析模型: SFS_k=5_GradientBoosting\n",
      "  方法: SFS, 模型: GradientBoosting, K=5\n",
      "  Test R²: 0.9071, Test MAE: 2.0734\n",
      "  准备模型数据: SFS_k=5_GradientBoosting\n",
      "    特征: ['Ω', 'mean_C4 enthalpy melting', 'var_C12 modulus Young', 'var_Space Group Number', 'Si_supersaturation']\n",
      "    特征索引: [7, 10, 19, 17, 29]\n",
      "    模型输入数据形状: (221, 5)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.0108, 61.3859]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 5)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493215\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493215\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 112: Base=12.081340, Step1_计算=12.683476, Step1_实际=12.683476, 匹配=True\n",
      "        样本 133: Base=12.081340, Step1_计算=12.761937, Step1_实际=12.761937, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=12.424750, Step1_实际=12.424750, 匹配=True\n",
      "        样本 35: Base=12.081340, Step1_计算=13.243008, Step1_实际=13.243008, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=26.726387, Step1_实际=26.726387, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493215\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=9.904194, Step1_实际=9.904194, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=26.726387, Step1_实际=26.726387, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=12.424750, Step1_实际=12.424750, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=7.985564, Step1_实际=7.985564, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=12.349742, Step1_实际=12.349742, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 SFS_k=5_GradientBoosting 分析完成 (耗时: 7.7秒)\n",
      "\n",
      "[10/11] 分析模型: SBS_k=4_GradientBoosting\n",
      "  方法: SBS, 模型: GradientBoosting, K=4\n",
      "  Test R²: 0.9054, Test MAE: 2.5126\n",
      "  准备模型数据: SBS_k=4_GradientBoosting\n",
      "    特征: ['Ω', 'mean_Mass Magnetic Susceptibility', 'var_Mass Magnetic Susceptibility', 'refractory_elements_sum']\n",
      "    特征索引: [7, 11, 24, 36]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.4565, 61.4905]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.081340271493213\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.081340271493213\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 221: Base=12.081340, Step1_计算=11.672258, Step1_实际=11.672258, 匹配=True\n",
      "        样本 157: Base=12.081340, Step1_计算=9.210234, Step1_实际=9.210234, 匹配=True\n",
      "        样本 24: Base=12.081340, Step1_计算=12.400798, Step1_实际=12.400798, 匹配=True\n",
      "        样本 187: Base=12.081340, Step1_计算=12.073894, Step1_实际=12.073894, 匹配=True\n",
      "        样本 7: Base=12.081340, Step1_计算=10.177865, Step1_实际=10.177865, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.081340271493213\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=11.254327, Step1_实际=11.254327, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=10.247178, Step1_实际=10.247178, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=10.614766, Step1_实际=10.614766, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=8.060629, Step1_实际=8.060629, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=11.422112, Step1_实际=11.422112, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 SBS_k=4_GradientBoosting 分析完成 (耗时: 7.3秒)\n",
      "\n",
      "[11/11] 分析模型: GA_k=4_GradientBoosting\n",
      "  方法: GA, 模型: GradientBoosting, K=4\n",
      "  Test R²: 0.9051, Test MAE: 2.1520\n",
      "  准备模型数据: GA_k=4_GradientBoosting\n",
      "    特征: ['Ω', 'mean_Mass Magnetic Susceptibility', 'var_C12 modulus Young', 'solubility_limit_factor']\n",
      "    特征索引: [7, 11, 19, 33]\n",
      "    模型输入数据形状: (221, 4)\n",
      "    使用数据类型: 原始数据\n",
      "    模型预测成功: [5.2751, 61.6516]\n",
      "  创建SHAP解释器...\n",
      "    ✓ TreeExplainer成功\n",
      "    SHAP值形状: (221, 4)\n",
      "  创建完整可视化...\n",
      "    创建完整SHAP可视化图表...\n",
      "      ✓ SHAP概要图\n",
      "      ✓ SHAP蜂群图\n",
      "      ✓ SHAP条形图\n",
      "      ✓ SHAP热图\n",
      "      创建SHAP瀑布图...\n",
      "      ✓ SHAP瀑布图 (10个样本)\n",
      "      创建SHAP决策图...\n",
      "      ✓ SHAP决策图\n",
      "  保存完整数据...\n",
      "    保存完整SHAP分析数据...\n",
      "      ✓ 特征重要性数据\n",
      "      创建概要图/蜂群图数据（宽格式）...\n",
      "      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\n",
      "      ✓ 概要图/蜂群图数据（长格式备份）\n",
      "      ✓ 热图数据\n",
      "      使用基准值: 12.08134027149322\n",
      "      ✓ 瀑布图数据 (前20个样本)\n",
      "      正在保存所有 221 个样本的瀑布图数据...\n",
      "      ✓ 瀑布图数据 (所有 221 个样本)\n",
      "      决策图基准值（随机样本）: 12.08134027149322\n",
      "      验证决策图数据计算（前5个样本）:\n",
      "        样本 58: Base=12.081340, Step1_计算=11.390406, Step1_实际=11.390406, 匹配=True\n",
      "        样本 87: Base=12.081340, Step1_计算=8.627549, Step1_实际=8.627549, 匹配=True\n",
      "        样本 194: Base=12.081340, Step1_计算=10.892375, Step1_实际=10.892375, 匹配=True\n",
      "        样本 117: Base=12.081340, Step1_计算=12.186866, Step1_实际=12.186866, 匹配=True\n",
      "        样本 130: Base=12.081340, Step1_计算=11.293144, Step1_实际=11.293144, 匹配=True\n",
      "      ✓ 决策图数据 (随机100个样本)\n",
      "      正在保存所有 221 个样本的决策图数据...\n",
      "      决策图基准值（所有样本）: 12.08134027149322\n",
      "      验证决策图数据计算（所有样本，前5个样本）:\n",
      "        样本 1: Base=12.081340, Step1_计算=9.255259, Step1_实际=9.255259, 匹配=True\n",
      "        样本 2: Base=12.081340, Step1_计算=12.086115, Step1_实际=12.086115, 匹配=True\n",
      "        样本 3: Base=12.081340, Step1_计算=9.977256, Step1_实际=9.977256, 匹配=True\n",
      "        样本 4: Base=12.081340, Step1_计算=8.012171, Step1_实际=8.012171, 匹配=True\n",
      "        样本 5: Base=12.081340, Step1_计算=14.049363, Step1_实际=14.049363, 匹配=True\n",
      "      ✓ 决策图数据 (所有 221 个样本)\n",
      "      ✓ 完整样本SHAP值数据\n",
      "      ✓ SHAP统计分析数据\n",
      "      ✓ 数据文件索引\n",
      "  ✓ 模型 GA_k=4_GradientBoosting 分析完成 (耗时: 7.2秒)\n",
      "\n",
      "=== 创建总体分析报告 ===\n",
      "\n",
      "=== 多模型SHAP分析完成（修复版）===\n",
      "🎉 总体结果:\n",
      "  📊 总模型数量: 11\n",
      "  ✅ 成功分析: 11\n",
      "  ❌ 失败分析: 0\n",
      "  📈 成功率: 100.0%\n",
      "  ⏱️ 总分析时间: 113.3秒 (1.9分钟)\n",
      "\n",
      "🔧 主要修复:\n",
      "  ✓ 决策图数据累积值计算错误修复\n",
      "    - 问题：Step_0_Cumulative 和 Step_1_Cumulative 显示相同值\n",
      "    - 修复：确保expected_value为标量，正确计算累积SHAP值\n",
      "    - 验证：添加累积值计算验证机制\n",
      "  ✓ 保持概要图数据宽格式（便于Origin使用）\n",
      "\n",
      "📁 输出结构:\n",
      "  主目录: D:\\博一下\\manuscript5-变Si组\\SHAP分析8.1.3\n",
      "  ├── SHAP_Analysis_Summary_Fixed.xlsx (分析结果汇总)\n",
      "  ├── Directory_Index_Fixed.xlsx (目录索引)\n",
      "  ├── Multi_Model_SHAP_Analysis_Report_Fixed.txt (总体报告)\n",
      "  ├── Model_01_PCC_k=5_GradientBoosting/ (模型 1)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_02_F-Regression_k=5_GradientBoosting/ (模型 2)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_03_RFE_k=4_GradientBoosting/ (模型 3)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_04_Mutual Information_k=5_GradientBoosting/ (模型 4)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_05_Lasso_k=4_GradientBoosting/ (模型 5)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_06_SFS_k=4_GradientBoosting/ (模型 6)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_07_RandomForest_k=4_GradientBoosting/ (模型 7)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_08_SFS_k=4_Bagging/ (模型 8)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_09_SFS_k=5_GradientBoosting/ (模型 9)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_10_SBS_k=4_GradientBoosting/ (模型 10)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "  ├── Model_11_GA_k=4_GradientBoosting/ (模型 11)\n",
      "  │   ├── 可视化文件 (15个PNG)\n",
      "  │   ├── 数据文件 (11个XLSX)【决策图数据已修复】\n",
      "  │   └── model_info.txt\n",
      "\n",
      "🎯 成功分析的模型:\n",
      "   1. 🎯 PCC_k=5_GradientBoosting\n",
      "      方法: PCC, 模型: GradientBoosting, K=5\n",
      "      Test R²: 0.9318, Test MAE: 2.0637\n",
      "      输出: Model_01_PCC_k=5_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   2. 🎯 F-Regression_k=5_GradientBoosting\n",
      "      方法: F-Regression, 模型: GradientBoosting, K=5\n",
      "      Test R²: 0.9197, Test MAE: 2.0991\n",
      "      输出: Model_02_F-Regression_k=5_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   3.   RFE_k=4_GradientBoosting\n",
      "      方法: RFE, 模型: GradientBoosting, K=4\n",
      "      Test R²: 0.9177, Test MAE: 2.2332\n",
      "      输出: Model_03_RFE_k=4_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   4.   Mutual Information_k=5_GradientBoosting\n",
      "      方法: Mutual Information, 模型: GradientBoosting, K=5\n",
      "      Test R²: 0.9157, Test MAE: 2.1871\n",
      "      输出: Model_04_Mutual Information_k=5_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   5.   Lasso_k=4_GradientBoosting\n",
      "      方法: Lasso, 模型: GradientBoosting, K=4\n",
      "      Test R²: 0.9149, Test MAE: 2.1957\n",
      "      输出: Model_05_Lasso_k=4_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   6.★🎯 SFS_k=4_GradientBoosting\n",
      "      方法: SFS, 模型: GradientBoosting, K=4\n",
      "      Test R²: 0.9103, Test MAE: 2.1015\n",
      "      输出: Model_06_SFS_k=4_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   7. 🎯 RandomForest_k=4_GradientBoosting\n",
      "      方法: RandomForest, 模型: GradientBoosting, K=4\n",
      "      Test R²: 0.9082, Test MAE: 2.1780\n",
      "      输出: Model_07_RandomForest_k=4_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   8.★🎯 SFS_k=4_Bagging\n",
      "      方法: SFS, 模型: Bagging, K=4\n",
      "      Test R²: 0.9080, Test MAE: 2.2937\n",
      "      输出: Model_08_SFS_k=4_Bagging\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "   9.★🎯 SFS_k=5_GradientBoosting\n",
      "      方法: SFS, 模型: GradientBoosting, K=5\n",
      "      Test R²: 0.9071, Test MAE: 2.0734\n",
      "      输出: Model_09_SFS_k=5_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "  10.★  SBS_k=4_GradientBoosting\n",
      "      方法: SBS, 模型: GradientBoosting, K=4\n",
      "      Test R²: 0.9054, Test MAE: 2.5126\n",
      "      输出: Model_10_SBS_k=4_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "  11.★🎯 GA_k=4_GradientBoosting\n",
      "      方法: GA, 模型: GradientBoosting, K=4\n",
      "      Test R²: 0.9051, Test MAE: 2.1520\n",
      "      输出: Model_11_GA_k=4_GradientBoosting\n",
      "      文件: 15个可视化 + 11个数据文件\n",
      "\n",
      "💡 Origin用户重点关注（修复版）:\n",
      "  📊 使用 shap_summary_beeswarm_data.xlsx (宽格式，便于Origin处理)\n",
      "    - 每行一个样本，每列一个特征的相关信息\n",
      "    - 包含特征值、SHAP值、标准化值\n",
      "    - 直接复制粘贴到Origin即可进行可视化\n",
      "  📈 决策图数据（已修复）:\n",
      "    - shap_decision_plot_data_all_samples.xlsx (推荐)\n",
      "    - 累积值计算已修复：Step_1_Cumulative = Base_Value + Step_1_SHAP\n",
      "    - 可以正确绘制决策图轨迹\n",
      "  📊 其他推荐文件:\n",
      "    - shap_feature_importance.xlsx (特征重要性)\n",
      "    - shap_waterfall_data_all_samples.xlsx (瀑布图数据)\n",
      "    - shap_statistical_analysis.xlsx (统计分析)\n",
      "\n",
      "✅ 多模型SHAP分析程序执行完成（修复版）!\n",
      "📁 所有结果已保存到: D:\\博一下\\manuscript5-变Si组\\SHAP分析8.1.3\n",
      "🕒 完成时间: 2025-08-02 21:24:38\n",
      "\n",
      "🔍 现在每个模型都有修复的SHAP分析内容:\n",
      "  - 6种可视化图表（概要图、蜂群图、条形图、热图、瀑布图、决策图）\n",
      "  - 11个数据文件（包括修复的决策图数据）\n",
      "  - 完整的统计分析和文件索引\n",
      "  - 详细的模型信息和配置\n",
      "✨ 特别修复了决策图数据累积值计算问题，现在可以正确用于Origin可视化！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ====================== 0. 自定义配色方案 ======================\n",
    "# 使用与原SHAP程序相同的9种颜色创建自定义配色方案\n",
    "custom_colors = [\n",
    "    (142/255, 1/255, 82/255),      # 紫红色\n",
    "    (201/255, 44/255, 134/255),    # 深粉色\n",
    "    (229/255, 144/255, 191/255),   # 中粉色\n",
    "    (248/255, 207/255, 231/255),   # 浅粉色\n",
    "    (248/255, 242/255, 245/255),   # 浅粉白色\n",
    "    (229/255, 245/255, 206/255),   # 极浅绿色\n",
    "    (170/255, 216/255, 117/255),   # 浅绿色\n",
    "    (104/255, 169/255, 50/255),    # 中绿色\n",
    "    (52/255, 116/255, 27/255)      # 深绿色\n",
    "]\n",
    "\n",
    "# 创建颜色映射\n",
    "custom_cmap_full = ListedColormap(custom_colors)\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_diverging\", custom_colors, N=256)\n",
    "\n",
    "# ====================== 1. 定义路径和参数 ======================\n",
    "# 输入路径（基于第一个程序的输出）\n",
    "model_dir = r\"D:\\博一下\\manuscript5-变Si组\\模型训练_K45_物理引导特征工程_无贝叶斯优化-7.29.3最终_修复版\"\n",
    "data_file = r\"D:\\文成数据库\\Nb-Si数据库3.4-成分-性能.xlsx\"\n",
    "\n",
    "# 输出路径（用户指定的保存地址）\n",
    "shap_output_dir = r\"D:\\博一下\\manuscript5-变Si组\\SHAP分析8.1.3\"\n",
    "\n",
    "# 创建SHAP输出目录\n",
    "if not os.path.exists(shap_output_dir):\n",
    "    os.makedirs(shap_output_dir)\n",
    "\n",
    "print(\"=== 开始多模型SHAP分析（修复版）===\")\n",
    "print(f\"输出目录: {shap_output_dir}\")\n",
    "print(f\"分析时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ====================== 2. 加载原始数据 ======================\n",
    "print(\"\\n=== 加载原始数据 ===\")\n",
    "df = pd.read_excel(data_file)\n",
    "print(f\"✓ 成功加载数据: {df.shape}\")\n",
    "\n",
    "# ====================== 3. 加载模型和相关数据 ======================\n",
    "print(\"\\n=== 加载所有最佳模型相关数据 ===\")\n",
    "\n",
    "try:\n",
    "    # 加载最佳模型列表\n",
    "    models_file = os.path.join(model_dir, 'best_models_physics_guided_no_bayesian_fixed.pkl')\n",
    "    with open(models_file, 'rb') as f:\n",
    "        best_models = pickle.load(f)\n",
    "    \n",
    "    # 加载特征名称列表\n",
    "    features_file = os.path.join(model_dir, 'features_name_physics_guided_no_bayesian_fixed.pkl')\n",
    "    with open(features_file, 'rb') as f:\n",
    "        all_features_name = pickle.load(f)\n",
    "    \n",
    "    # 加载标准化器\n",
    "    scaler_file = os.path.join(model_dir, 'scaler_physics_guided_no_bayesian_fixed.pkl')\n",
    "    scaler = joblib.load(scaler_file)\n",
    "    \n",
    "    # 加载数据信息\n",
    "    data_file_path = os.path.join(model_dir, 'data_info_physics_guided_no_bayesian_fixed.pkl')\n",
    "    with open(data_file_path, 'rb') as f:\n",
    "        data_info = pickle.load(f)\n",
    "    \n",
    "    print(\"✓ 成功加载所有保存的数据\")\n",
    "    print(f\"✓ 找到 {len(best_models)} 个最佳模型\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 加载保存数据失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# ====================== 4. 数据预处理函数 ======================\n",
    "def prepare_shap_data_for_model(model_info, all_features_name, df, data_info, scaler):\n",
    "    \"\"\"\n",
    "    为特定模型准备SHAP分析数据\n",
    "    \"\"\"\n",
    "    print(f\"  准备模型数据: {model_info['model_key']}\")\n",
    "    \n",
    "    # 获取模型的特征\n",
    "    features = model_info['features']\n",
    "    sel_idx = model_info['sel_idx']\n",
    "    \n",
    "    print(f\"    特征: {features}\")\n",
    "    print(f\"    特征索引: {sel_idx}\")\n",
    "    \n",
    "    try:\n",
    "        # 识别哪些是原始特征，哪些是物理工程特征\n",
    "        original_excel_features = df.columns.tolist()\n",
    "        \n",
    "        # 分类特征\n",
    "        original_features = []      # 存在于原始Excel中的特征\n",
    "        physics_features = []       # 物理工程生成的特征\n",
    "        original_indices = []       # 原始特征在all_features_name中的索引\n",
    "        physics_indices = []        # 物理特征在all_features_name中的索引\n",
    "        \n",
    "        for i, feature in enumerate(all_features_name):\n",
    "            if feature in original_excel_features:\n",
    "                original_features.append(feature)\n",
    "                original_indices.append(i)\n",
    "            else:\n",
    "                physics_features.append(feature)\n",
    "                physics_indices.append(i)\n",
    "        \n",
    "        # 1. 从原始Excel文件提取原始特征\n",
    "        if len(original_features) > 0:\n",
    "            X_original_from_excel = df[original_features].values\n",
    "            y_from_excel = df['KQ'].values\n",
    "            \n",
    "            # 移除NaN值\n",
    "            nan_mask_x_orig = ~np.isnan(X_original_from_excel).any(axis=1)\n",
    "            nan_mask_y = ~np.isnan(y_from_excel)\n",
    "            valid_mask_excel = nan_mask_x_orig & nan_mask_y\n",
    "            \n",
    "            X_original_clean = X_original_from_excel[valid_mask_excel]\n",
    "            y_all_clean = y_from_excel[valid_mask_excel]\n",
    "        else:\n",
    "            X_original_clean = None\n",
    "            y_all_clean = data_info['y_all_np']\n",
    "        \n",
    "        # 2. 从保存的训练数据提取物理工程特征\n",
    "        if len(physics_features) > 0:\n",
    "            # 根据模型类型选择合适的数据源\n",
    "            if model_info['is_tree_based']:\n",
    "                saved_data = data_info['X_all_original']\n",
    "            else:\n",
    "                saved_data = data_info['X_all_scaled']\n",
    "            \n",
    "            # 提取物理特征\n",
    "            X_physics_from_saved = saved_data[:, physics_indices]\n",
    "            \n",
    "            # 确保样本数量一致\n",
    "            if X_original_clean is not None:\n",
    "                min_samples = min(X_original_clean.shape[0], X_physics_from_saved.shape[0])\n",
    "                X_original_clean = X_original_clean[:min_samples]\n",
    "                X_physics_from_saved = X_physics_from_saved[:min_samples]\n",
    "                y_all_clean = y_all_clean[:min_samples]\n",
    "        else:\n",
    "            X_physics_from_saved = None\n",
    "        \n",
    "        # 3. 合并数据并保持正确的特征顺序\n",
    "        if X_original_clean is not None and X_physics_from_saved is not None:\n",
    "            # 创建完整的特征矩阵，按照all_features_name的顺序\n",
    "            X_all_clean = np.zeros((X_original_clean.shape[0], len(all_features_name)))\n",
    "            \n",
    "            # 填入原始特征\n",
    "            for i, orig_idx in enumerate(original_indices):\n",
    "                X_all_clean[:, orig_idx] = X_original_clean[:, i]\n",
    "            \n",
    "            # 填入物理特征\n",
    "            for i, phys_idx in enumerate(physics_indices):\n",
    "                X_all_clean[:, phys_idx] = X_physics_from_saved[:, i]\n",
    "            \n",
    "        elif X_original_clean is not None:\n",
    "            X_all_clean = X_original_clean\n",
    "        elif X_physics_from_saved is not None:\n",
    "            X_all_clean = X_physics_from_saved\n",
    "        else:\n",
    "            raise ValueError(\"无法获取任何特征数据\")\n",
    "        \n",
    "        # 验证数据完整性\n",
    "        if np.any(np.isnan(X_all_clean)):\n",
    "            nan_mask = ~np.isnan(X_all_clean).any(axis=1)\n",
    "            X_all_clean = X_all_clean[nan_mask]\n",
    "            y_all_clean = y_all_clean[nan_mask]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    智能数据提取失败: {e}\")\n",
    "        print(\"    回退到保存数据方案...\")\n",
    "        \n",
    "        # 回退方案：完全使用保存的训练数据\n",
    "        if model_info['is_tree_based']:\n",
    "            X_all_clean = data_info['X_all_original']\n",
    "        else:\n",
    "            X_all_clean = data_info['X_all_scaled'] \n",
    "        \n",
    "        y_all_clean = data_info['y_all_np']\n",
    "    \n",
    "    # 选择模型使用的特征\n",
    "    if model_info['is_tree_based']:\n",
    "        # 树模型使用原始数据\n",
    "        X_model = X_all_clean[:, sel_idx]\n",
    "        final_data_type = \"原始数据\"\n",
    "    else:\n",
    "        # 其他模型使用标准化数据\n",
    "        X_all_clean = scaler.transform(X_all_clean)\n",
    "        X_model = X_all_clean[:, sel_idx]\n",
    "        final_data_type = \"标准化数据\"\n",
    "    \n",
    "    print(f\"    模型输入数据形状: {X_model.shape}\")\n",
    "    print(f\"    使用数据类型: {final_data_type}\")\n",
    "    \n",
    "    # 验证模型预测\n",
    "    try:\n",
    "        model = model_info['model_instance']\n",
    "        predictions = model.predict(X_model)\n",
    "        print(f\"    模型预测成功: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "        \n",
    "        # 确保数据类型正确\n",
    "        X_model = X_model.astype(np.float64)\n",
    "        \n",
    "        # 检查是否存在极值\n",
    "        if np.any(np.isinf(X_model)) or np.any(np.isnan(X_model)):\n",
    "            finite_mask = np.all(np.isfinite(X_model), axis=1)\n",
    "            X_model = X_model[finite_mask]\n",
    "            y_all_clean = y_all_clean[finite_mask]\n",
    "            print(f\"    清理后数据形状: X{X_model.shape}, y{y_all_clean.shape}\")\n",
    "        \n",
    "        return X_model, y_all_clean, model, features, final_data_type\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    模型预测失败: {e}\")\n",
    "        raise\n",
    "\n",
    "# ====================== 5. SHAP可视化函数（完整版本）======================\n",
    "def create_shap_visualizations(shap_values, X_model, features, model_output_dir, model_key, explainer, model, y_all_clean):\n",
    "    \"\"\"\n",
    "    创建完整的SHAP可视化图表（与原版程序相同）\n",
    "    \"\"\"\n",
    "    print(f\"    创建完整SHAP可视化图表...\")\n",
    "    \n",
    "    # 设置matplotlib参数\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    plt.rcParams['savefig.dpi'] = 300\n",
    "    try:\n",
    "        plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    visualization_files = []\n",
    "    \n",
    "    # 5.1 SHAP概要图 (Summary Plot)\n",
    "    try:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        shap.summary_plot(\n",
    "            shap_values, \n",
    "            X_model, \n",
    "            feature_names=features, \n",
    "            show=False, \n",
    "            max_display=len(features),\n",
    "            cmap=custom_cmap,\n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "        plt.title(f'SHAP 特征影响概要图 - {model_key}', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('SHAP值 (特征对输出的影响)', fontsize=12)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "        plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        plt.figtext(0.13, 0.02, \n",
    "                    \"说明: 紫色系表示特征值低→结果减小，绿色系表示特征值高→结果增大\", \n",
    "                    fontsize=10, color='dimgray')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        summary_file = os.path.join(model_output_dir, 'shap_summary_plot.png')\n",
    "        plt.savefig(summary_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        visualization_files.append(summary_file)\n",
    "        print(f\"      ✓ SHAP概要图\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP概要图失败: {e}\")\n",
    "    \n",
    "    # 5.2 SHAP蜂群图 (Beeswarm Plot)\n",
    "    try:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        shap.summary_plot(\n",
    "            shap_values, \n",
    "            X_model, \n",
    "            feature_names=features, \n",
    "            show=False, \n",
    "            max_display=len(features),\n",
    "            plot_type=\"dot\",\n",
    "            cmap=custom_cmap,\n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "        plt.title(f'SHAP 蜂群图 - {model_key}', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('SHAP值 (特征对输出的影响)', fontsize=12)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "        plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        beeswarm_file = os.path.join(model_output_dir, 'shap_beeswarm_plot.png')\n",
    "        plt.savefig(beeswarm_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        visualization_files.append(beeswarm_file)\n",
    "        print(f\"      ✓ SHAP蜂群图\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP蜂群图失败: {e}\")\n",
    "    \n",
    "    # 5.3 SHAP条形图 (Bar Plot)\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        shap.summary_plot(\n",
    "            shap_values, \n",
    "            X_model, \n",
    "            feature_names=features, \n",
    "            plot_type='bar', \n",
    "            show=False, \n",
    "            max_display=len(features),\n",
    "            color=custom_colors[8]\n",
    "        )\n",
    "        \n",
    "        plt.title(f'SHAP 特征重要性条形图 - {model_key}', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('平均|SHAP值|', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        bar_file = os.path.join(model_output_dir, 'shap_bar_plot.png')\n",
    "        plt.savefig(bar_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        visualization_files.append(bar_file)\n",
    "        print(f\"      ✓ SHAP条形图\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP条形图失败: {e}\")\n",
    "    \n",
    "    # 5.4 SHAP热图\n",
    "    try:\n",
    "        # 计算特征重要性排序\n",
    "        mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "        importance_order = np.argsort(mean_abs_shap)[::-1]\n",
    "        \n",
    "        # 限制样本数量以防止图像过大\n",
    "        max_samples_heatmap = min(200, shap_values.shape[0])\n",
    "        sample_indices = np.random.choice(shap_values.shape[0], max_samples_heatmap, replace=False)\n",
    "        \n",
    "        # 按重要性排序重新排列数据\n",
    "        ordered_shap_values = shap_values[sample_indices][:, importance_order]\n",
    "        ordered_feature_names = [features[i] for i in importance_order]\n",
    "        \n",
    "        plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # 创建热图\n",
    "        im = plt.imshow(ordered_shap_values.T, aspect='auto', cmap=custom_cmap, interpolation='none')\n",
    "        \n",
    "        # 添加颜色条\n",
    "        cbar = plt.colorbar(im, label='SHAP值')\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "        \n",
    "        # 设置标题和标签\n",
    "        plt.title(f'SHAP 热图 - {model_key} (按特征重要性排序)', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('样本', fontsize=12)\n",
    "        plt.ylabel('特征 (按重要性排序)', fontsize=12)\n",
    "        \n",
    "        # 设置y轴刻度为特征名称\n",
    "        plt.yticks(range(len(ordered_feature_names)), ordered_feature_names, fontsize=10)\n",
    "        plt.xticks(fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        heatmap_file = os.path.join(model_output_dir, 'shap_heatmap.png')\n",
    "        plt.savefig(heatmap_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        visualization_files.append(heatmap_file)\n",
    "        print(f\"      ✓ SHAP热图\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP热图失败: {e}\")\n",
    "    \n",
    "    # 5.5 SHAP瀑布图 (Waterfall Plot) - 多个样本\n",
    "    try:\n",
    "        print(f\"      创建SHAP瀑布图...\")\n",
    "        waterfall_samples = min(10, shap_values.shape[0])\n",
    "        \n",
    "        for i in range(waterfall_samples):\n",
    "            try:\n",
    "                plt.figure(figsize=(14, 10))\n",
    "                \n",
    "                # 获取基准值\n",
    "                if hasattr(explainer, 'expected_value'):\n",
    "                    expected_value = explainer.expected_value\n",
    "                else:\n",
    "                    expected_value = model.predict(X_model).mean()\n",
    "                \n",
    "                # 获取预测值\n",
    "                prediction = model.predict(X_model[i:i+1])[0]\n",
    "                \n",
    "                # 创建瀑布图\n",
    "                shap.plots.waterfall(\n",
    "                    shap.Explanation(\n",
    "                        values=shap_values[i],\n",
    "                        base_values=expected_value,\n",
    "                        data=X_model[i],\n",
    "                        feature_names=features\n",
    "                    ),\n",
    "                    show=False,\n",
    "                    max_display=len(features)\n",
    "                )\n",
    "                \n",
    "                plt.title(f'SHAP 瀑布图 - {model_key} - 样本 {i+1} (预测值: {prediction:.4f})', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                waterfall_file = os.path.join(model_output_dir, f'shap_waterfall_sample_{i+1}.png')\n",
    "                plt.savefig(waterfall_file, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                visualization_files.append(waterfall_file)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"        ❌ 样本 {i+1} 瀑布图失败: {e}\")\n",
    "        \n",
    "        print(f\"      ✓ SHAP瀑布图 ({waterfall_samples}个样本)\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP瀑布图失败: {e}\")\n",
    "    \n",
    "    # 5.6 SHAP决策图 (Decision Plot)\n",
    "    try:\n",
    "        print(f\"      创建SHAP决策图...\")\n",
    "        \n",
    "        # 限制样本数量以便可视化\n",
    "        decision_samples = min(100, shap_values.shape[0])\n",
    "        sample_indices = np.random.choice(shap_values.shape[0], decision_samples, replace=False)\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # 获取基准值\n",
    "        if hasattr(explainer, 'expected_value'):\n",
    "            expected_value = explainer.expected_value\n",
    "        else:\n",
    "            expected_value = model.predict(X_model).mean()\n",
    "        \n",
    "        # 创建决策图\n",
    "        shap.decision_plot(\n",
    "            expected_value,\n",
    "            shap_values[sample_indices],\n",
    "            features=features,\n",
    "            show=False,\n",
    "            highlight=0  # 高亮第一个样本\n",
    "        )\n",
    "        \n",
    "        plt.title(f'SHAP 决策图 - {model_key} ({decision_samples}个样本)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('模型输出', fontsize=12)\n",
    "        plt.ylabel('特征', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        decision_file = os.path.join(model_output_dir, 'shap_decision_plot.png')\n",
    "        plt.savefig(decision_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        visualization_files.append(decision_file)\n",
    "        print(f\"      ✓ SHAP决策图\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP决策图失败: {e}\")\n",
    "    \n",
    "    return visualization_files\n",
    "\n",
    "# ====================== 6. SHAP数据保存函数（修复版本）======================\n",
    "def save_shap_data(shap_values, X_model, y_all_clean, features, model, explainer, model_output_dir, model_key):\n",
    "    \"\"\"\n",
    "    保存完整的SHAP分析数据（修复决策图数据格式问题）\n",
    "    \"\"\"\n",
    "    print(f\"    保存完整SHAP分析数据...\")\n",
    "    \n",
    "    data_files = []\n",
    "    \n",
    "    # 计算基础统计\n",
    "    mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "    \n",
    "    # 6.1 特征重要性数据（对应条形图）\n",
    "    try:\n",
    "        shap_importance_df = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Mean_Absolute_SHAP_Value': mean_abs_shap,\n",
    "            'Relative_Importance': mean_abs_shap / np.sum(mean_abs_shap) * 100,\n",
    "            'Rank': range(1, len(features) + 1)\n",
    "        })\n",
    "        shap_importance_df = shap_importance_df.sort_values('Mean_Absolute_SHAP_Value', ascending=False)\n",
    "        shap_importance_df['Rank'] = range(1, len(features) + 1)\n",
    "        \n",
    "        importance_file = os.path.join(model_output_dir, 'shap_feature_importance.xlsx')\n",
    "        shap_importance_df.to_excel(importance_file, index=False)\n",
    "        data_files.append(importance_file)\n",
    "        print(f\"      ✓ 特征重要性数据\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 特征重要性数据失败: {e}\")\n",
    "    \n",
    "    # 6.2 概要图/蜂群图数据（修改为宽格式）\n",
    "    try:\n",
    "        print(f\"      创建概要图/蜂群图数据（宽格式）...\")\n",
    "        \n",
    "        # 创建宽格式数据框\n",
    "        summary_data_wide = {\n",
    "            'Sample_Index': list(range(1, X_model.shape[0] + 1)),\n",
    "            'Actual_KQ': y_all_clean,\n",
    "            'Predicted_KQ': model.predict(X_model)\n",
    "        }\n",
    "        \n",
    "        # 为每个特征添加三列：特征值、SHAP值、标准化特征值\n",
    "        for feature_idx, feature_name in enumerate(features):\n",
    "            # 特征值\n",
    "            summary_data_wide[f'{feature_name}_Value'] = X_model[:, feature_idx]\n",
    "            \n",
    "            # SHAP值\n",
    "            summary_data_wide[f'{feature_name}_SHAP'] = shap_values[:, feature_idx]\n",
    "            \n",
    "            # 标准化特征值（0-1标准化）\n",
    "            feature_values = X_model[:, feature_idx]\n",
    "            if feature_values.max() != feature_values.min():\n",
    "                normalized_values = (feature_values - feature_values.min()) / (feature_values.max() - feature_values.min())\n",
    "            else:\n",
    "                normalized_values = np.full_like(feature_values, 0.5)\n",
    "            summary_data_wide[f'{feature_name}_Normalized'] = normalized_values\n",
    "        \n",
    "        summary_df_wide = pd.DataFrame(summary_data_wide)\n",
    "        summary_file_wide = os.path.join(model_output_dir, 'shap_summary_beeswarm_data.xlsx')\n",
    "        summary_df_wide.to_excel(summary_file_wide, index=False)\n",
    "        data_files.append(summary_file_wide)\n",
    "        print(f\"      ✓ 概要图/蜂群图数据（宽格式，便于Origin处理）\")\n",
    "        \n",
    "        # 同时保存长格式版本，以备需要\n",
    "        summary_data_long = []\n",
    "        for sample_idx in range(X_model.shape[0]):\n",
    "            for feature_idx, feature_name in enumerate(features):\n",
    "                summary_data_long.append({\n",
    "                    'Sample_Index': sample_idx + 1,\n",
    "                    'Feature_Name': feature_name,\n",
    "                    'Feature_Value': X_model[sample_idx, feature_idx],\n",
    "                    'SHAP_Value': shap_values[sample_idx, feature_idx],\n",
    "                    'Feature_Value_Normalized': (X_model[sample_idx, feature_idx] - X_model[:, feature_idx].min()) / \n",
    "                                              (X_model[:, feature_idx].max() - X_model[:, feature_idx].min()) if X_model[:, feature_idx].max() != X_model[:, feature_idx].min() else 0.5,\n",
    "                    'Actual_KQ': y_all_clean[sample_idx],\n",
    "                    'Predicted_KQ': model.predict(X_model[sample_idx:sample_idx+1])[0]\n",
    "                })\n",
    "        \n",
    "        summary_df_long = pd.DataFrame(summary_data_long)\n",
    "        summary_file_long = os.path.join(model_output_dir, 'shap_summary_beeswarm_data_long_format.xlsx')\n",
    "        summary_df_long.to_excel(summary_file_long, index=False)\n",
    "        data_files.append(summary_file_long)\n",
    "        print(f\"      ✓ 概要图/蜂群图数据（长格式备份）\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 概要图/蜂群图数据失败: {e}\")\n",
    "    \n",
    "    # 6.3 热图数据\n",
    "    try:\n",
    "        importance_order = np.argsort(mean_abs_shap)[::-1]\n",
    "        ordered_feature_names = [features[i] for i in importance_order]\n",
    "        ordered_shap_values = shap_values[:, importance_order]\n",
    "        \n",
    "        heatmap_df = pd.DataFrame(ordered_shap_values, columns=ordered_feature_names)\n",
    "        heatmap_df.insert(0, 'Sample_Index', range(1, len(X_model) + 1))\n",
    "        heatmap_df.insert(1, 'Actual_KQ', y_all_clean)\n",
    "        heatmap_df.insert(2, 'Predicted_KQ', model.predict(X_model))\n",
    "        \n",
    "        # 添加特征值（按重要性排序）\n",
    "        ordered_feature_values = X_model[:, importance_order]\n",
    "        for i, feature_name in enumerate(ordered_feature_names):\n",
    "            heatmap_df[f'{feature_name}_Value'] = ordered_feature_values[:, i]\n",
    "        \n",
    "        heatmap_file = os.path.join(model_output_dir, 'shap_heatmap_data.xlsx')\n",
    "        heatmap_df.to_excel(heatmap_file, index=False)\n",
    "        data_files.append(heatmap_file)\n",
    "        print(f\"      ✓ 热图数据\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 热图数据失败: {e}\")\n",
    "    \n",
    "    # 6.4 瀑布图数据（前20个样本）\n",
    "    try:\n",
    "        waterfall_data = []\n",
    "        \n",
    "        # 获取基准值 - 🔧 修复：确保是标量\n",
    "        if hasattr(explainer, 'expected_value'):\n",
    "            expected_value = explainer.expected_value\n",
    "            if isinstance(expected_value, (list, np.ndarray)):\n",
    "                expected_value = float(expected_value[0])\n",
    "            else:\n",
    "                expected_value = float(expected_value)\n",
    "        else:\n",
    "            expected_value = float(model.predict(X_model).mean())\n",
    "        \n",
    "        print(f\"      使用基准值: {expected_value}\")\n",
    "        \n",
    "        # 保存前20个样本的瀑布图数据\n",
    "        waterfall_samples = min(20, X_model.shape[0])\n",
    "        for i in range(waterfall_samples):\n",
    "            prediction = model.predict(X_model[i:i+1])[0]\n",
    "            \n",
    "            # 基础数据\n",
    "            sample_data = {\n",
    "                'Sample_Index': i + 1,\n",
    "                'Base_Value': expected_value,\n",
    "                'Prediction': prediction,\n",
    "                'Actual_KQ': y_all_clean[i],\n",
    "                'Total_SHAP_Effect': np.sum(shap_values[i]),\n",
    "                'Prediction_Error': prediction - y_all_clean[i],\n",
    "                'Absolute_Prediction_Error': abs(prediction - y_all_clean[i])\n",
    "            }\n",
    "            \n",
    "            # 每个特征的SHAP值和特征值\n",
    "            for j, feature in enumerate(features):\n",
    "                sample_data[f'SHAP_{feature}'] = shap_values[i, j]\n",
    "                sample_data[f'Value_{feature}'] = X_model[i, j]\n",
    "            \n",
    "            # 按SHAP绝对值排序的特征贡献\n",
    "            abs_shap = np.abs(shap_values[i])\n",
    "            sorted_indices = np.argsort(abs_shap)[::-1]\n",
    "            \n",
    "            cumulative_effect = expected_value\n",
    "            for rank, j in enumerate(sorted_indices):\n",
    "                feature = features[j]\n",
    "                feature_effect = shap_values[i, j]\n",
    "                cumulative_effect += feature_effect\n",
    "                \n",
    "                sample_data[f'Rank_{rank+1}_Feature'] = feature\n",
    "                sample_data[f'Rank_{rank+1}_SHAP'] = feature_effect\n",
    "                sample_data[f'Rank_{rank+1}_Value'] = X_model[i, j]\n",
    "                sample_data[f'Rank_{rank+1}_Abs_SHAP'] = abs(feature_effect)\n",
    "                sample_data[f'Cumulative_After_Rank_{rank+1}'] = cumulative_effect\n",
    "            \n",
    "            waterfall_data.append(sample_data)\n",
    "        \n",
    "        waterfall_df = pd.DataFrame(waterfall_data)\n",
    "        waterfall_file = os.path.join(model_output_dir, 'shap_waterfall_data.xlsx')\n",
    "        waterfall_df.to_excel(waterfall_file, index=False)\n",
    "        data_files.append(waterfall_file)\n",
    "        print(f\"      ✓ 瀑布图数据 (前{waterfall_samples}个样本)\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 瀑布图数据失败: {e}\")\n",
    "    \n",
    "    # 6.5 瀑布图数据（所有样本）\n",
    "    try:\n",
    "        print(f\"      正在保存所有 {X_model.shape[0]} 个样本的瀑布图数据...\")\n",
    "        \n",
    "        waterfall_data_all = []\n",
    "        \n",
    "        # 获取基准值 - 🔧 修复：确保是标量\n",
    "        if hasattr(explainer, 'expected_value'):\n",
    "            expected_value = explainer.expected_value\n",
    "            if isinstance(expected_value, (list, np.ndarray)):\n",
    "                expected_value = float(expected_value[0])\n",
    "            else:\n",
    "                expected_value = float(expected_value)\n",
    "        else:\n",
    "            expected_value = float(model.predict(X_model).mean())\n",
    "        \n",
    "        for i in range(X_model.shape[0]):\n",
    "            prediction = model.predict(X_model[i:i+1])[0]\n",
    "            \n",
    "            # 基础数据\n",
    "            sample_data = {\n",
    "                'Sample_Index': i + 1,\n",
    "                'Base_Value': expected_value,\n",
    "                'Prediction': prediction,\n",
    "                'Actual_KQ': y_all_clean[i],\n",
    "                'Total_SHAP_Effect': np.sum(shap_values[i]),\n",
    "                'Prediction_Error': prediction - y_all_clean[i],\n",
    "                'Absolute_Prediction_Error': abs(prediction - y_all_clean[i])\n",
    "            }\n",
    "            \n",
    "            # 每个特征的SHAP值和特征值\n",
    "            for j, feature in enumerate(features):\n",
    "                sample_data[f'SHAP_{feature}'] = shap_values[i, j]\n",
    "                sample_data[f'Value_{feature}'] = X_model[i, j]\n",
    "            \n",
    "            # 按SHAP绝对值排序的特征贡献\n",
    "            abs_shap = np.abs(shap_values[i])\n",
    "            sorted_indices = np.argsort(abs_shap)[::-1]\n",
    "            \n",
    "            cumulative_effect = expected_value\n",
    "            for rank, j in enumerate(sorted_indices):\n",
    "                feature = features[j]\n",
    "                feature_effect = shap_values[i, j]\n",
    "                cumulative_effect += feature_effect\n",
    "                \n",
    "                sample_data[f'Rank_{rank+1}_Feature'] = feature\n",
    "                sample_data[f'Rank_{rank+1}_SHAP'] = feature_effect\n",
    "                sample_data[f'Rank_{rank+1}_Value'] = X_model[i, j]\n",
    "                sample_data[f'Rank_{rank+1}_Abs_SHAP'] = abs(feature_effect)\n",
    "                sample_data[f'Cumulative_After_Rank_{rank+1}'] = cumulative_effect\n",
    "            \n",
    "            waterfall_data_all.append(sample_data)\n",
    "        \n",
    "        waterfall_df_all = pd.DataFrame(waterfall_data_all)\n",
    "        waterfall_file_all = os.path.join(model_output_dir, 'shap_waterfall_data_all_samples.xlsx')\n",
    "        waterfall_df_all.to_excel(waterfall_file_all, index=False)\n",
    "        data_files.append(waterfall_file_all)\n",
    "        print(f\"      ✓ 瀑布图数据 (所有 {X_model.shape[0]} 个样本)\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 瀑布图数据（所有样本）失败: {e}\")\n",
    "    \n",
    "    # 6.6 决策图数据（随机100个样本）- 🔧 修复版本\n",
    "    try:\n",
    "        decision_samples = min(100, X_model.shape[0])\n",
    "        sample_indices_decision = np.random.choice(X_model.shape[0], decision_samples, replace=False)\n",
    "        \n",
    "        # 获取基准值 - 🔧 修复：确保是标量\n",
    "        if hasattr(explainer, 'expected_value'):\n",
    "            expected_value = explainer.expected_value\n",
    "            if isinstance(expected_value, (list, np.ndarray)):\n",
    "                expected_value = float(expected_value[0])\n",
    "            else:\n",
    "                expected_value = float(expected_value)\n",
    "        else:\n",
    "            expected_value = float(model.predict(X_model).mean())\n",
    "        \n",
    "        print(f\"      决策图基准值（随机样本）: {expected_value}\")\n",
    "        \n",
    "        decision_data = []\n",
    "        for i in sample_indices_decision:\n",
    "            sample_data = {\n",
    "                'Sample_Index': i + 1,\n",
    "                'Base_Value': expected_value,\n",
    "                'Prediction': model.predict(X_model[i:i+1])[0],\n",
    "                'Actual_KQ': y_all_clean[i],\n",
    "                'Prediction_Error': model.predict(X_model[i:i+1])[0] - y_all_clean[i],\n",
    "                'Absolute_Prediction_Error': abs(model.predict(X_model[i:i+1])[0] - y_all_clean[i])\n",
    "            }\n",
    "            \n",
    "            # 🔧 修复：累积SHAP效应（按特征重要性顺序）\n",
    "            cumulative_shap = expected_value  # 确保是标量\n",
    "            sample_data['Step_0_Cumulative'] = cumulative_shap\n",
    "            sample_data['Step_0_Feature'] = 'Base_Value'\n",
    "            \n",
    "            importance_order = np.argsort(mean_abs_shap)[::-1]\n",
    "            for step, j in enumerate(importance_order):\n",
    "                feature = features[j]\n",
    "                shap_contribution = float(shap_values[i, j])  # 🔧 确保是标量\n",
    "                cumulative_shap += shap_contribution\n",
    "                \n",
    "                sample_data[f'Step_{step+1}_Feature'] = feature\n",
    "                sample_data[f'Step_{step+1}_SHAP'] = shap_contribution\n",
    "                sample_data[f'Step_{step+1}_Value'] = float(X_model[i, j])\n",
    "                sample_data[f'Step_{step+1}_Cumulative'] = cumulative_shap  # 🔧 这里应该是正确的累积值\n",
    "                sample_data[f'Step_{step+1}_SHAP_Abs'] = abs(shap_contribution)\n",
    "            \n",
    "            # 添加最终验证\n",
    "            sample_data['Final_Cumulative'] = cumulative_shap\n",
    "            sample_data['Cumulative_Equals_Prediction'] = abs(cumulative_shap - sample_data['Prediction']) < 1e-6\n",
    "            \n",
    "            decision_data.append(sample_data)\n",
    "        \n",
    "        # 🔧 添加验证输出（前5个样本）\n",
    "        print(f\"      验证决策图数据计算（前5个样本）:\")\n",
    "        for idx in range(min(5, len(decision_data))):\n",
    "            sample = decision_data[idx]\n",
    "            step_1_calculated = sample['Step_0_Cumulative'] + sample['Step_1_SHAP']\n",
    "            print(f\"        样本 {sample['Sample_Index']}: Base={sample['Base_Value']:.6f}, \"\n",
    "                  f\"Step1_计算={step_1_calculated:.6f}, Step1_实际={sample['Step_1_Cumulative']:.6f}, \"\n",
    "                  f\"匹配={abs(step_1_calculated - sample['Step_1_Cumulative']) < 1e-6}\")\n",
    "        \n",
    "        decision_df = pd.DataFrame(decision_data)\n",
    "        decision_file = os.path.join(model_output_dir, 'shap_decision_plot_data.xlsx')\n",
    "        decision_df.to_excel(decision_file, index=False)\n",
    "        data_files.append(decision_file)\n",
    "        print(f\"      ✓ 决策图数据 (随机{decision_samples}个样本)\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 决策图数据失败: {e}\")\n",
    "    \n",
    "    # 6.7 决策图数据（所有样本）- 🔧 修复版本\n",
    "    try:\n",
    "        print(f\"      正在保存所有 {X_model.shape[0]} 个样本的决策图数据...\")\n",
    "        \n",
    "        # 获取基准值 - 🔧 修复：确保是标量\n",
    "        if hasattr(explainer, 'expected_value'):\n",
    "            expected_value = explainer.expected_value\n",
    "            if isinstance(expected_value, (list, np.ndarray)):\n",
    "                expected_value = float(expected_value[0])\n",
    "            else:\n",
    "                expected_value = float(expected_value)\n",
    "        else:\n",
    "            expected_value = float(model.predict(X_model).mean())\n",
    "        \n",
    "        print(f\"      决策图基准值（所有样本）: {expected_value}\")\n",
    "        \n",
    "        decision_data_all = []\n",
    "        for i in range(X_model.shape[0]):\n",
    "            sample_data = {\n",
    "                'Sample_Index': i + 1,\n",
    "                'Base_Value': expected_value,\n",
    "                'Prediction': model.predict(X_model[i:i+1])[0],\n",
    "                'Actual_KQ': y_all_clean[i],\n",
    "                'Prediction_Error': model.predict(X_model[i:i+1])[0] - y_all_clean[i],\n",
    "                'Absolute_Prediction_Error': abs(model.predict(X_model[i:i+1])[0] - y_all_clean[i])\n",
    "            }\n",
    "            \n",
    "            # 🔧 修复：累积SHAP效应（按特征重要性顺序）\n",
    "            cumulative_shap = expected_value  # 确保是标量\n",
    "            sample_data['Step_0_Cumulative'] = cumulative_shap\n",
    "            sample_data['Step_0_Feature'] = 'Base_Value'\n",
    "            \n",
    "            importance_order = np.argsort(mean_abs_shap)[::-1]\n",
    "            for step, j in enumerate(importance_order):\n",
    "                feature = features[j]\n",
    "                shap_contribution = float(shap_values[i, j])  # 🔧 确保是标量\n",
    "                cumulative_shap += shap_contribution\n",
    "                \n",
    "                sample_data[f'Step_{step+1}_Feature'] = feature\n",
    "                sample_data[f'Step_{step+1}_SHAP'] = shap_contribution\n",
    "                sample_data[f'Step_{step+1}_Value'] = float(X_model[i, j])\n",
    "                sample_data[f'Step_{step+1}_Cumulative'] = cumulative_shap  # 🔧 这里应该是正确的累积值\n",
    "                sample_data[f'Step_{step+1}_SHAP_Abs'] = abs(shap_contribution)\n",
    "            \n",
    "            # 添加最终验证\n",
    "            sample_data['Final_Cumulative'] = cumulative_shap\n",
    "            sample_data['Cumulative_Equals_Prediction'] = abs(cumulative_shap - sample_data['Prediction']) < 1e-6\n",
    "            \n",
    "            decision_data_all.append(sample_data)\n",
    "        \n",
    "        # 🔧 添加验证输出（前5个样本）\n",
    "        print(f\"      验证决策图数据计算（所有样本，前5个样本）:\")\n",
    "        for idx in range(min(5, len(decision_data_all))):\n",
    "            sample = decision_data_all[idx]\n",
    "            step_1_calculated = sample['Step_0_Cumulative'] + sample['Step_1_SHAP']\n",
    "            print(f\"        样本 {sample['Sample_Index']}: Base={sample['Base_Value']:.6f}, \"\n",
    "                  f\"Step1_计算={step_1_calculated:.6f}, Step1_实际={sample['Step_1_Cumulative']:.6f}, \"\n",
    "                  f\"匹配={abs(step_1_calculated - sample['Step_1_Cumulative']) < 1e-6}\")\n",
    "        \n",
    "        decision_df_all = pd.DataFrame(decision_data_all)\n",
    "        decision_file_all = os.path.join(model_output_dir, 'shap_decision_plot_data_all_samples.xlsx')\n",
    "        decision_df_all.to_excel(decision_file_all, index=False)\n",
    "        data_files.append(decision_file_all)\n",
    "        print(f\"      ✓ 决策图数据 (所有 {X_model.shape[0]} 个样本)\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 决策图数据（所有样本）失败: {e}\")\n",
    "    \n",
    "    # 6.8 每个样本的完整SHAP值\n",
    "    try:\n",
    "        # 原始特征值\n",
    "        sample_data_df = pd.DataFrame(X_model, columns=features)\n",
    "        sample_data_df.insert(0, 'Sample_Index', range(1, len(X_model) + 1))\n",
    "        sample_data_df.insert(1, 'Actual_KQ', y_all_clean)\n",
    "        sample_data_df.insert(2, 'Predicted_KQ', model.predict(X_model))\n",
    "        \n",
    "        # SHAP值\n",
    "        shap_values_df = pd.DataFrame(shap_values, columns=[f'SHAP_{col}' for col in features])\n",
    "        \n",
    "        # 计算每个样本的SHAP统计\n",
    "        shap_stats_df = pd.DataFrame({\n",
    "            'Total_SHAP_Effect': np.sum(shap_values, axis=1),\n",
    "            'Total_Absolute_SHAP': np.sum(np.abs(shap_values), axis=1),\n",
    "            'Max_Positive_SHAP': np.max(np.where(shap_values > 0, shap_values, 0), axis=1),\n",
    "            'Max_Negative_SHAP': np.min(np.where(shap_values < 0, shap_values, 0), axis=1),\n",
    "            'SHAP_Range': np.max(shap_values, axis=1) - np.min(shap_values, axis=1)\n",
    "        })\n",
    "        \n",
    "        # 合并所有数据\n",
    "        combined_df = pd.concat([sample_data_df, shap_values_df, shap_stats_df], axis=1)\n",
    "        complete_file = os.path.join(model_output_dir, 'shap_values_all_samples.xlsx')\n",
    "        combined_df.to_excel(complete_file, index=False)\n",
    "        data_files.append(complete_file)\n",
    "        print(f\"      ✓ 完整样本SHAP值数据\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 完整样本SHAP值数据失败: {e}\")\n",
    "    \n",
    "    # 6.9 SHAP统计分析\n",
    "    try:\n",
    "        stats_data = []\n",
    "        for i, feature in enumerate(features):\n",
    "            feature_shap = shap_values[:, i]\n",
    "            feature_values = X_model[:, i]\n",
    "            \n",
    "            # 计算分位数\n",
    "            shap_percentiles = np.percentile(feature_shap, [10, 25, 50, 75, 90])\n",
    "            value_percentiles = np.percentile(feature_values, [10, 25, 50, 75, 90])\n",
    "            \n",
    "            stats_data.append({\n",
    "                'Feature': feature,\n",
    "                'SHAP_Mean': np.mean(feature_shap),\n",
    "                'SHAP_Std': np.std(feature_shap),\n",
    "                'SHAP_Min': np.min(feature_shap),\n",
    "                'SHAP_Max': np.max(feature_shap),\n",
    "                'SHAP_10th_Percentile': shap_percentiles[0],\n",
    "                'SHAP_25th_Percentile': shap_percentiles[1],\n",
    "                'SHAP_Median': shap_percentiles[2],\n",
    "                'SHAP_75th_Percentile': shap_percentiles[3],\n",
    "                'SHAP_90th_Percentile': shap_percentiles[4],\n",
    "                'SHAP_Mean_Abs': np.mean(np.abs(feature_shap)),\n",
    "                'Feature_Mean': np.mean(feature_values),\n",
    "                'Feature_Std': np.std(feature_values),\n",
    "                'Feature_Min': np.min(feature_values),\n",
    "                'Feature_Max': np.max(feature_values),\n",
    "                'Feature_10th_Percentile': value_percentiles[0],\n",
    "                'Feature_25th_Percentile': value_percentiles[1],\n",
    "                'Feature_Median': value_percentiles[2],\n",
    "                'Feature_75th_Percentile': value_percentiles[3],\n",
    "                'Feature_90th_Percentile': value_percentiles[4],\n",
    "                'SHAP_Feature_Correlation': np.corrcoef(feature_values, feature_shap)[0, 1],\n",
    "                'Relative_Importance': mean_abs_shap[i] / np.sum(mean_abs_shap) * 100,\n",
    "                'Positive_SHAP_Count': np.sum(feature_shap > 0),\n",
    "                'Negative_SHAP_Count': np.sum(feature_shap < 0),\n",
    "                'Zero_SHAP_Count': np.sum(feature_shap == 0),\n",
    "                'Positive_SHAP_Percentage': np.sum(feature_shap > 0) / len(feature_shap) * 100,\n",
    "                'Negative_SHAP_Percentage': np.sum(feature_shap < 0) / len(feature_shap) * 100\n",
    "            })\n",
    "        \n",
    "        stats_df = pd.DataFrame(stats_data)\n",
    "        stats_df = stats_df.sort_values('SHAP_Mean_Abs', ascending=False)\n",
    "        stats_file = os.path.join(model_output_dir, 'shap_statistical_analysis.xlsx')\n",
    "        stats_df.to_excel(stats_file, index=False)\n",
    "        data_files.append(stats_file)\n",
    "        print(f\"      ✓ SHAP统计分析数据\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ SHAP统计分析数据失败: {e}\")\n",
    "    \n",
    "    # 6.10 数据文件索引（更新）\n",
    "    try:\n",
    "        file_index = {\n",
    "            'File_Name': [\n",
    "                'shap_feature_importance.xlsx',\n",
    "                'shap_summary_beeswarm_data.xlsx',\n",
    "                'shap_summary_beeswarm_data_long_format.xlsx',\n",
    "                'shap_heatmap_data.xlsx',\n",
    "                'shap_waterfall_data.xlsx',\n",
    "                'shap_waterfall_data_all_samples.xlsx',\n",
    "                'shap_decision_plot_data.xlsx',\n",
    "                'shap_decision_plot_data_all_samples.xlsx',\n",
    "                'shap_values_all_samples.xlsx',\n",
    "                'shap_statistical_analysis.xlsx'\n",
    "            ],\n",
    "            'Corresponding_Visualization': [\n",
    "                'SHAP条形图 (Bar Plot)',\n",
    "                'SHAP概要图 & 蜂群图 (Summary Plot & Beeswarm Plot)',\n",
    "                'SHAP概要图 & 蜂群图 (Summary Plot & Beeswarm Plot)',\n",
    "                'SHAP热图 (Heatmap)',\n",
    "                'SHAP瀑布图 (Waterfall Plot) - 前20个样本',\n",
    "                'SHAP瀑布图 (Waterfall Plot) - 所有样本',\n",
    "                'SHAP决策图 (Decision Plot) - 随机100个样本',\n",
    "                'SHAP决策图 (Decision Plot) - 所有样本',\n",
    "                '所有样本完整数据 (All Samples Complete Data)',\n",
    "                'SHAP统计分析 (Statistical Analysis)'\n",
    "            ],\n",
    "            'Description': [\n",
    "                '特征重要性排序，平均绝对SHAP值',\n",
    "                '每个样本每个特征的SHAP值和特征值，用于创建散点图（宽格式，推荐用于Origin）',\n",
    "                '每个样本每个特征的SHAP值和特征值，用于创建散点图（长格式，备份）',\n",
    "                '按特征重要性排序的SHAP值矩阵，包含样本和特征信息',\n",
    "                '瀑布图所需的累积SHAP效应数据，包含前20个样本',\n",
    "                '瀑布图所需的累积SHAP效应数据，包含所有样本（Origin推荐）',\n",
    "                '决策路径数据，显示SHAP值的累积过程，包含随机100个样本（已修复累积值计算）',\n",
    "                '决策路径数据，显示SHAP值的累积过程，包含所有样本（Origin推荐，已修复累积值计算）',\n",
    "                '所有样本的完整特征值、SHAP值和预测信息',\n",
    "                '详细的SHAP值统计分析，包含分位数、相关性等指标'\n",
    "            ],\n",
    "            'Sample_Count': [\n",
    "                f'{len(features)}个特征',\n",
    "                f'{X_model.shape[0]}个样本（行）× {len(features)*3+3}列（每特征3列+基础3列）',\n",
    "                f'{X_model.shape[0]}个样本 × {len(features)}个特征',\n",
    "                f'{X_model.shape[0]}个样本 × {len(features)}个特征',\n",
    "                '20个样本',\n",
    "                f'{X_model.shape[0]}个样本',\n",
    "                '100个样本',\n",
    "                f'{X_model.shape[0]}个样本',\n",
    "                f'{X_model.shape[0]}个样本',\n",
    "                f'{len(features)}个特征的统计指标'\n",
    "            ],\n",
    "            'Origin_Recommended': [\n",
    "                '是',\n",
    "                '是（主要推荐，宽格式）', \n",
    "                '否（备份，长格式）',\n",
    "                '是',\n",
    "                '否（样本有限）',\n",
    "                '是（推荐使用）',\n",
    "                '否（样本有限）',\n",
    "                '是（推荐使用，已修复）',\n",
    "                '是',\n",
    "                '是'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        index_df = pd.DataFrame(file_index)\n",
    "        index_file = os.path.join(model_output_dir, 'data_files_index.xlsx')\n",
    "        index_df.to_excel(index_file, index=False)\n",
    "        data_files.append(index_file)\n",
    "        print(f\"      ✓ 数据文件索引\")\n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 数据文件索引失败: {e}\")\n",
    "    \n",
    "    return data_files\n",
    "\n",
    "# ====================== 7. 单个模型SHAP分析函数 ======================\n",
    "def analyze_single_model_shap(model_info, model_index, total_models, all_features_name, df, data_info, scaler, shap_output_dir):\n",
    "    \"\"\"\n",
    "    对单个模型进行完整的SHAP分析\n",
    "    \"\"\"\n",
    "    print(f\"\\n[{model_index+1}/{total_models}] 分析模型: {model_info['model_key']}\")\n",
    "    print(f\"  方法: {model_info['method']}, 模型: {model_info['model']}, K={model_info['k']}\")\n",
    "    print(f\"  Test R²: {model_info['test_r2']:.4f}, Test MAE: {model_info['test_mae']:.4f}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 为每个模型创建单独的输出目录\n",
    "    model_safe_name = model_info['model_key'].replace('/', '_').replace('\\\\', '_').replace(':', '_')\n",
    "    model_output_dir = os.path.join(shap_output_dir, f\"Model_{model_index+1:02d}_{model_safe_name}\")\n",
    "    if not os.path.exists(model_output_dir):\n",
    "        os.makedirs(model_output_dir)\n",
    "    \n",
    "    try:\n",
    "        # 1. 准备数据\n",
    "        X_model, y_all_clean, model, features, final_data_type = prepare_shap_data_for_model(\n",
    "            model_info, all_features_name, df, data_info, scaler\n",
    "        )\n",
    "        \n",
    "        # 2. 创建SHAP解释器并计算SHAP值\n",
    "        print(f\"  创建SHAP解释器...\")\n",
    "        try:\n",
    "            # 优先使用TreeExplainer\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_model)\n",
    "            print(f\"    ✓ TreeExplainer成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"    TreeExplainer失败，尝试Explainer: {e}\")\n",
    "            try:\n",
    "                explainer = shap.Explainer(model)\n",
    "                shap_values = explainer(X_model)\n",
    "                if hasattr(shap_values, 'values'):\n",
    "                    shap_values = shap_values.values\n",
    "                print(f\"    ✓ Explainer成功\")\n",
    "            except Exception as e2:\n",
    "                print(f\"    Explainer失败，使用KernelExplainer: {e2}\")\n",
    "                bg_samples = min(100, X_model.shape[0])\n",
    "                bg_data = X_model[:bg_samples]\n",
    "                explainer = shap.KernelExplainer(model.predict, bg_data)\n",
    "                shap_values = explainer.shap_values(X_model)\n",
    "                print(f\"    ✓ KernelExplainer成功\")\n",
    "        \n",
    "        # 确保SHAP值是正确的格式\n",
    "        if len(shap_values.shape) > 2:\n",
    "            shap_values = np.squeeze(shap_values)\n",
    "        \n",
    "        print(f\"    SHAP值形状: {shap_values.shape}\")\n",
    "        \n",
    "        # 3. 创建完整可视化（包含所有6种类型）\n",
    "        print(f\"  创建完整可视化...\")\n",
    "        visualization_files = create_shap_visualizations(\n",
    "            shap_values, X_model, features, model_output_dir, model_info['model_key'], \n",
    "            explainer, model, y_all_clean\n",
    "        )\n",
    "        \n",
    "        # 4. 保存完整数据（包含修复后的决策图数据）\n",
    "        print(f\"  保存完整数据...\")\n",
    "        data_files = save_shap_data(\n",
    "            shap_values, X_model, y_all_clean, features, model, explainer, model_output_dir, model_info['model_key']\n",
    "        )\n",
    "        \n",
    "        # 5. 保存模型信息\n",
    "        model_info_data = {\n",
    "            'Model_Key': model_info['model_key'],\n",
    "            'Method': model_info['method'],\n",
    "            'ML_Model': model_info['model'],\n",
    "            'K': model_info['k'],\n",
    "            'Train_R2': model_info['train_r2'],\n",
    "            'Test_R2': model_info['test_r2'],\n",
    "            'Train_MAE': model_info['train_mae'],\n",
    "            'Test_MAE': model_info['test_mae'],\n",
    "            'Train_RMSLE': model_info['train_rmsle'],\n",
    "            'Test_RMSLE': model_info['test_rmsle'],\n",
    "            'Is_Tree_Based': model_info['is_tree_based'],\n",
    "            'Is_Advanced_Method': model_info['is_advanced'],\n",
    "            'Is_Focus_Combination': model_info['is_focus_combination'],\n",
    "            'Data_Type': final_data_type,\n",
    "            'Total_Samples': X_model.shape[0],\n",
    "            'Features': features,\n",
    "            'Selected_Indices': model_info['sel_idx']\n",
    "        }\n",
    "        \n",
    "        # 保存模型信息到文本文件\n",
    "        with open(os.path.join(model_output_dir, 'model_info.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=== 模型SHAP分析信息（修复版）===\\n\\n\")\n",
    "            for key, value in model_info_data.items():\n",
    "                if key == 'Features':\n",
    "                    f.write(f\"{key}:\\n\")\n",
    "                    for i, feature in enumerate(value, 1):\n",
    "                        f.write(f\"  {i}. {feature}\\n\")\n",
    "                elif key == 'Selected_Indices':\n",
    "                    f.write(f\"{key}: {value}\\n\")\n",
    "                else:\n",
    "                    f.write(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n=== SHAP分析结果文件 ===\\n\")\n",
    "            f.write(f\"可视化文件:\\n\")\n",
    "            f.write(f\"  1. shap_summary_plot.png - SHAP概要图\\n\")\n",
    "            f.write(f\"  2. shap_beeswarm_plot.png - SHAP蜂群图\\n\")\n",
    "            f.write(f\"  3. shap_bar_plot.png - SHAP条形图\\n\")\n",
    "            f.write(f\"  4. shap_heatmap.png - SHAP热图\\n\")\n",
    "            f.write(f\"  5. shap_waterfall_sample_*.png - SHAP瀑布图 (多个样本)\\n\")\n",
    "            f.write(f\"  6. shap_decision_plot.png - SHAP决策图\\n\")\n",
    "            f.write(f\"\\n数据文件:\\n\")\n",
    "            f.write(f\"  1. shap_feature_importance.xlsx - 特征重要性数据\\n\")\n",
    "            f.write(f\"  2. shap_summary_beeswarm_data.xlsx - 概要图/蜂群图数据（宽格式，推荐用于Origin）\\n\")\n",
    "            f.write(f\"  3. shap_summary_beeswarm_data_long_format.xlsx - 概要图/蜂群图数据（长格式备份）\\n\")\n",
    "            f.write(f\"  4. shap_heatmap_data.xlsx - 热图数据\\n\")\n",
    "            f.write(f\"  5. shap_waterfall_data.xlsx - 瀑布图数据 (前20个样本)\\n\")\n",
    "            f.write(f\"  6. shap_waterfall_data_all_samples.xlsx - 瀑布图数据 (所有样本)\\n\")\n",
    "            f.write(f\"  7. shap_decision_plot_data.xlsx - 决策图数据 (随机100个样本)\\n\")\n",
    "            f.write(f\"  8. shap_decision_plot_data_all_samples.xlsx - 决策图数据 (所有样本)【已修复】\\n\")\n",
    "            f.write(f\"  9. shap_values_all_samples.xlsx - 完整样本SHAP值\\n\")\n",
    "            f.write(f\"  10. shap_statistical_analysis.xlsx - SHAP统计分析\\n\")\n",
    "            f.write(f\"  11. data_files_index.xlsx - 数据文件索引\\n\")\n",
    "            f.write(f\"\\n=== 🔧 主要修复 ===\\n\")\n",
    "            f.write(f\"1. 修复了决策图数据中累积值计算错误的问题\\n\")\n",
    "            f.write(f\"   - Step_0_Cumulative = Base_Value (正确)\\n\")\n",
    "            f.write(f\"   - Step_1_Cumulative = Base_Value + Step_1_SHAP (修复后)\\n\")\n",
    "            f.write(f\"   - Step_N_Cumulative = 前一步累积值 + Step_N_SHAP (修复后)\\n\")\n",
    "            f.write(f\"2. 确保基准值(expected_value)是标量而非数组格式\\n\")\n",
    "            f.write(f\"3. 添加了累积值计算的验证机制\\n\")\n",
    "            f.write(f\"4. 保持宽格式概要图数据便于Origin使用\\n\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"  ✓ 模型 {model_info['model_key']} 分析完成 (耗时: {elapsed_time:.1f}秒)\")\n",
    "        \n",
    "        return {\n",
    "            'model_key': model_info['model_key'],\n",
    "            'output_dir': model_output_dir,\n",
    "            'visualization_files': visualization_files,\n",
    "            'data_files': data_files,\n",
    "            'model_info': model_info_data,\n",
    "            'success': True,\n",
    "            'error': None,\n",
    "            'elapsed_time': elapsed_time\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"  ❌ 模型 {model_info['model_key']} 分析失败: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'model_key': model_info['model_key'],\n",
    "            'output_dir': model_output_dir,\n",
    "            'visualization_files': [],\n",
    "            'data_files': [],\n",
    "            'model_info': None,\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'elapsed_time': elapsed_time\n",
    "        }\n",
    "\n",
    "# ====================== 8. 主分析流程 ======================\n",
    "print(f\"\\n=== 开始多模型SHAP分析（修复版）===\")\n",
    "print(f\"总计模型数量: {len(best_models)}\")\n",
    "\n",
    "all_results = []\n",
    "successful_analyses = 0\n",
    "failed_analyses = 0\n",
    "\n",
    "# 分析每个模型\n",
    "for i, model_info in enumerate(best_models):\n",
    "    result = analyze_single_model_shap(\n",
    "        model_info, i, len(best_models), all_features_name, df, data_info, scaler, shap_output_dir\n",
    "    )\n",
    "    all_results.append(result)\n",
    "    \n",
    "    if result['success']:\n",
    "        successful_analyses += 1\n",
    "    else:\n",
    "        failed_analyses += 1\n",
    "\n",
    "# ====================== 9. 创建总体分析报告 ======================\n",
    "print(f\"\\n=== 创建总体分析报告 ===\")\n",
    "\n",
    "# 9.1 创建总体结果汇总\n",
    "summary_data = []\n",
    "for result in all_results:\n",
    "    if result['success']:\n",
    "        model_info = result['model_info']\n",
    "        summary_data.append({\n",
    "            'Model_Index': len(summary_data) + 1,\n",
    "            'Model_Key': result['model_key'],\n",
    "            'Method': model_info['Method'],\n",
    "            'ML_Model': model_info['ML_Model'],\n",
    "            'K': model_info['K'],\n",
    "            'Test_R2': model_info['Test_R2'],\n",
    "            'Test_MAE': model_info['Test_MAE'],\n",
    "            'Is_Advanced_Method': model_info['Is_Advanced_Method'],\n",
    "            'Is_Focus_Combination': model_info['Is_Focus_Combination'],\n",
    "            'Output_Directory': os.path.basename(result['output_dir']),\n",
    "            'Visualization_Count': len(result['visualization_files']),\n",
    "            'Data_File_Count': len(result['data_files']),\n",
    "            'Analysis_Time_Seconds': result['elapsed_time'],\n",
    "            'Features': ', '.join(model_info['Features']),\n",
    "            'Total_Samples': model_info['Total_Samples']\n",
    "        })\n",
    "    else:\n",
    "        summary_data.append({\n",
    "            'Model_Index': len(summary_data) + 1,\n",
    "            'Model_Key': result['model_key'],\n",
    "            'Method': 'N/A',\n",
    "            'ML_Model': 'N/A',\n",
    "            'K': 'N/A',\n",
    "            'Test_R2': 'N/A',\n",
    "            'Test_MAE': 'N/A',\n",
    "            'Is_Advanced_Method': 'N/A',\n",
    "            'Is_Focus_Combination': 'N/A',\n",
    "            'Output_Directory': 'FAILED',\n",
    "            'Visualization_Count': 0,\n",
    "            'Data_File_Count': 0,\n",
    "            'Analysis_Time_Seconds': result['elapsed_time'],\n",
    "            'Features': f'FAILED: {result[\"error\"]}',\n",
    "            'Total_Samples': 'N/A'\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_file = os.path.join(shap_output_dir, 'SHAP_Analysis_Summary_Fixed.xlsx')\n",
    "summary_df.to_excel(summary_file, index=False)\n",
    "\n",
    "# 9.2 创建目录索引\n",
    "directory_index = []\n",
    "for result in all_results:\n",
    "    if result['success']:\n",
    "        directory_index.append({\n",
    "            'Model_Key': result['model_key'],\n",
    "            'Directory_Name': os.path.basename(result['output_dir']),\n",
    "            'Full_Path': result['output_dir'],\n",
    "            'Visualization_Count': len(result['visualization_files']),\n",
    "            'Data_File_Count': len(result['data_files']),\n",
    "            'Status': 'SUCCESS'\n",
    "        })\n",
    "    else:\n",
    "        directory_index.append({\n",
    "            'Model_Key': result['model_key'],\n",
    "            'Directory_Name': 'FAILED',\n",
    "            'Full_Path': result['output_dir'],\n",
    "            'Visualization_Count': 0,\n",
    "            'Data_File_Count': 0,\n",
    "            'Status': f'FAILED: {result[\"error\"]}'\n",
    "        })\n",
    "\n",
    "directory_df = pd.DataFrame(directory_index)\n",
    "directory_file = os.path.join(shap_output_dir, 'Directory_Index_Fixed.xlsx')\n",
    "directory_df.to_excel(directory_file, index=False)\n",
    "\n",
    "# 9.3 创建总体报告文件\n",
    "total_time = sum(result['elapsed_time'] for result in all_results)\n",
    "with open(os.path.join(shap_output_dir, 'Multi_Model_SHAP_Analysis_Report_Fixed.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=== 多模型SHAP分析总体报告（修复版）===\\n\\n\")\n",
    "    f.write(f\"分析时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"总分析时间: {total_time:.1f} 秒 ({total_time/60:.1f} 分钟)\\n\\n\")\n",
    "    \n",
    "    f.write(f\"=== 🔧 主要修复 ===\\n\")\n",
    "    f.write(f\"✓ 决策图数据累积值计算错误修复\\n\")\n",
    "    f.write(f\"  - 问题：Step_0_Cumulative 和 Step_1_Cumulative 显示相同值\\n\")\n",
    "    f.write(f\"  - 原因：expected_value 数组格式导致累积计算错误\\n\")\n",
    "    f.write(f\"  - 修复：确保 expected_value 为标量，正确计算累积SHAP值\\n\")\n",
    "    f.write(f\"  - 验证：添加累积值计算验证，确保数据正确性\\n\\n\")\n",
    "    \n",
    "    f.write(f\"✓ 数据格式优化（保持之前改进）\\n\")\n",
    "    f.write(f\"  - shap_summary_beeswarm_data.xlsx 使用宽格式\\n\")\n",
    "    f.write(f\"  - 每行代表一个样本（而非每行一个特征-样本组合）\\n\")\n",
    "    f.write(f\"  - 每个特征有3列：特征名_Value, 特征名_SHAP, 特征名_Normalized\\n\")\n",
    "    f.write(f\"  - 更便于在Origin等软件中进行数据处理和可视化\\n\\n\")\n",
    "    \n",
    "    f.write(f\"=== 分析统计 ===\\n\")\n",
    "    f.write(f\"总模型数量: {len(best_models)}\\n\")\n",
    "    f.write(f\"成功分析: {successful_analyses}\\n\")\n",
    "    f.write(f\"失败分析: {failed_analyses}\\n\")\n",
    "    f.write(f\"成功率: {successful_analyses/len(best_models)*100:.1f}%\\n\\n\")\n",
    "    \n",
    "    f.write(f\"=== 成功分析的模型 ===\\n\")\n",
    "    for i, result in enumerate(all_results):\n",
    "        if result['success']:\n",
    "            model_info = result['model_info']\n",
    "            f.write(f\"{i+1}. {result['model_key']}\\n\")\n",
    "            f.write(f\"   方法: {model_info['Method']}, 模型: {model_info['ML_Model']}, K={model_info['K']}\\n\")\n",
    "            f.write(f\"   Test R²: {model_info['Test_R2']:.4f}, Test MAE: {model_info['Test_MAE']:.4f}\\n\")\n",
    "            f.write(f\"   输出目录: {os.path.basename(result['output_dir'])}\\n\")\n",
    "            f.write(f\"   可视化文件: {len(result['visualization_files'])}个\\n\")\n",
    "            f.write(f\"   数据文件: {len(result['data_files'])}个\\n\")\n",
    "            f.write(f\"   分析时间: {result['elapsed_time']:.1f}秒\\n\\n\")\n",
    "    \n",
    "    if failed_analyses > 0:\n",
    "        f.write(f\"=== 失败分析的模型 ===\\n\")\n",
    "        for i, result in enumerate(all_results):\n",
    "            if not result['success']:\n",
    "                f.write(f\"{i+1}. {result['model_key']}\\n\")\n",
    "                f.write(f\"   错误: {result['error']}\\n\")\n",
    "                f.write(f\"   尝试时间: {result['elapsed_time']:.1f}秒\\n\\n\")\n",
    "    \n",
    "    f.write(f\"=== 输出文件说明 ===\\n\")\n",
    "    f.write(f\"1. SHAP_Analysis_Summary_Fixed.xlsx - 所有模型的分析结果汇总\\n\")\n",
    "    f.write(f\"2. Directory_Index_Fixed.xlsx - 输出目录索引\\n\")\n",
    "    f.write(f\"3. Multi_Model_SHAP_Analysis_Report_Fixed.txt - 本报告文件\\n\")\n",
    "    f.write(f\"4. Model_XX_[模型名]/ - 每个模型的详细SHAP分析结果\\n\\n\")\n",
    "    \n",
    "    f.write(f\"=== 每个模型目录包含的文件（修复版）===\\n\")\n",
    "    f.write(f\"可视化文件 (6种类型):\\n\")\n",
    "    f.write(f\"  - shap_summary_plot.png (SHAP概要图)\\n\")\n",
    "    f.write(f\"  - shap_beeswarm_plot.png (SHAP蜂群图)\\n\")\n",
    "    f.write(f\"  - shap_bar_plot.png (SHAP条形图)\\n\")\n",
    "    f.write(f\"  - shap_heatmap.png (SHAP热图)\\n\")\n",
    "    f.write(f\"  - shap_waterfall_sample_*.png (SHAP瀑布图，多个样本)\\n\")\n",
    "    f.write(f\"  - shap_decision_plot.png (SHAP决策图)\\n\\n\")\n",
    "    f.write(f\"数据文件 (11个文件):\\n\")\n",
    "    f.write(f\"  - shap_feature_importance.xlsx (特征重要性数据)\\n\")\n",
    "    f.write(f\"  - shap_summary_beeswarm_data.xlsx (概要图/蜂群图数据-宽格式【推荐用于Origin】)\\n\")\n",
    "    f.write(f\"  - shap_summary_beeswarm_data_long_format.xlsx (概要图/蜂群图数据-长格式备份)\\n\")\n",
    "    f.write(f\"  - shap_heatmap_data.xlsx (热图数据)\\n\")\n",
    "    f.write(f\"  - shap_waterfall_data.xlsx (瀑布图数据-前20个样本)\\n\")\n",
    "    f.write(f\"  - shap_waterfall_data_all_samples.xlsx (瀑布图数据-所有样本)\\n\")\n",
    "    f.write(f\"  - shap_decision_plot_data.xlsx (决策图数据-随机100个样本)\\n\")\n",
    "    f.write(f\"  - shap_decision_plot_data_all_samples.xlsx (决策图数据-所有样本【已修复累积值计算】)\\n\")\n",
    "    f.write(f\"  - shap_values_all_samples.xlsx (完整SHAP值数据)\\n\")\n",
    "    f.write(f\"  - shap_statistical_analysis.xlsx (统计分析数据)\\n\")\n",
    "    f.write(f\"  - data_files_index.xlsx (数据文件索引)\\n\")\n",
    "    f.write(f\"  - model_info.txt (模型信息)\\n\\n\")\n",
    "\n",
    "# ====================== 10. 输出最终结果 ======================\n",
    "print(f\"\\n=== 多模型SHAP分析完成（修复版）===\")\n",
    "print(f\"🎉 总体结果:\")\n",
    "print(f\"  📊 总模型数量: {len(best_models)}\")\n",
    "print(f\"  ✅ 成功分析: {successful_analyses}\")\n",
    "print(f\"  ❌ 失败分析: {failed_analyses}\")\n",
    "print(f\"  📈 成功率: {successful_analyses/len(best_models)*100:.1f}%\")\n",
    "print(f\"  ⏱️ 总分析时间: {total_time:.1f}秒 ({total_time/60:.1f}分钟)\")\n",
    "\n",
    "print(f\"\\n🔧 主要修复:\")\n",
    "print(f\"  ✓ 决策图数据累积值计算错误修复\")\n",
    "print(f\"    - 问题：Step_0_Cumulative 和 Step_1_Cumulative 显示相同值\")\n",
    "print(f\"    - 修复：确保expected_value为标量，正确计算累积SHAP值\")\n",
    "print(f\"    - 验证：添加累积值计算验证机制\")\n",
    "print(f\"  ✓ 保持概要图数据宽格式（便于Origin使用）\")\n",
    "\n",
    "print(f\"\\n📁 输出结构:\")\n",
    "print(f\"  主目录: {shap_output_dir}\")\n",
    "print(f\"  ├── SHAP_Analysis_Summary_Fixed.xlsx (分析结果汇总)\")\n",
    "print(f\"  ├── Directory_Index_Fixed.xlsx (目录索引)\")\n",
    "print(f\"  ├── Multi_Model_SHAP_Analysis_Report_Fixed.txt (总体报告)\")\n",
    "for i, result in enumerate(all_results):\n",
    "    if result['success']:\n",
    "        dir_name = os.path.basename(result['output_dir'])\n",
    "        print(f\"  ├── {dir_name}/ (模型 {i+1})\")\n",
    "        print(f\"  │   ├── 可视化文件 ({len(result['visualization_files'])}个PNG)\")\n",
    "        print(f\"  │   ├── 数据文件 ({len(result['data_files'])}个XLSX)【决策图数据已修复】\")\n",
    "        print(f\"  │   └── model_info.txt\")\n",
    "\n",
    "if successful_analyses > 0:\n",
    "    print(f\"\\n🎯 成功分析的模型:\")\n",
    "    for i, result in enumerate(all_results):\n",
    "        if result['success']:\n",
    "            model_info = result['model_info']\n",
    "            advanced_mark = \"★\" if model_info['Is_Advanced_Method'] else \" \"\n",
    "            focus_mark = \"🎯\" if model_info['Is_Focus_Combination'] else \" \"\n",
    "            \n",
    "            print(f\"  {i+1:2d}.{advanced_mark}{focus_mark} {result['model_key']}\")\n",
    "            print(f\"      方法: {model_info['Method']}, 模型: {model_info['ML_Model']}, K={model_info['K']}\")\n",
    "            print(f\"      Test R²: {model_info['Test_R2']:.4f}, Test MAE: {model_info['Test_MAE']:.4f}\")\n",
    "            print(f\"      输出: {os.path.basename(result['output_dir'])}\")\n",
    "            print(f\"      文件: {len(result['visualization_files'])}个可视化 + {len(result['data_files'])}个数据文件\")\n",
    "\n",
    "if failed_analyses > 0:\n",
    "    print(f\"\\n❌ 失败分析的模型:\")\n",
    "    for i, result in enumerate(all_results):\n",
    "        if not result['success']:\n",
    "            print(f\"  {i+1:2d}. {result['model_key']}\")\n",
    "            print(f\"      错误: {result['error']}\")\n",
    "\n",
    "print(f\"\\n💡 Origin用户重点关注（修复版）:\")\n",
    "print(f\"  📊 使用 shap_summary_beeswarm_data.xlsx (宽格式，便于Origin处理)\")\n",
    "print(f\"    - 每行一个样本，每列一个特征的相关信息\")\n",
    "print(f\"    - 包含特征值、SHAP值、标准化值\")\n",
    "print(f\"    - 直接复制粘贴到Origin即可进行可视化\")\n",
    "print(f\"  📈 决策图数据（已修复）:\")\n",
    "print(f\"    - shap_decision_plot_data_all_samples.xlsx (推荐)\")\n",
    "print(f\"    - 累积值计算已修复：Step_1_Cumulative = Base_Value + Step_1_SHAP\")\n",
    "print(f\"    - 可以正确绘制决策图轨迹\")\n",
    "print(f\"  📊 其他推荐文件:\")\n",
    "print(f\"    - shap_feature_importance.xlsx (特征重要性)\")\n",
    "print(f\"    - shap_waterfall_data_all_samples.xlsx (瀑布图数据)\")\n",
    "print(f\"    - shap_statistical_analysis.xlsx (统计分析)\")\n",
    "\n",
    "print(f\"\\n✅ 多模型SHAP分析程序执行完成（修复版）!\")\n",
    "print(f\"📁 所有结果已保存到: {shap_output_dir}\")\n",
    "print(f\"🕒 完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\n🔍 现在每个模型都有修复的SHAP分析内容:\")\n",
    "print(f\"  - 6种可视化图表（概要图、蜂群图、条形图、热图、瀑布图、决策图）\")\n",
    "print(f\"  - 11个数据文件（包括修复的决策图数据）\")\n",
    "print(f\"  - 完整的统计分析和文件索引\")\n",
    "print(f\"  - 详细的模型信息和配置\")\n",
    "print(f\"✨ 特别修复了决策图数据累积值计算问题，现在可以正确用于Origin可视化！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
